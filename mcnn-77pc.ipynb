{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a757f3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange, repeat\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# --- CONFIGURATION (Safe & Fast) ---\n",
    "ROOT_DIR = '/kaggle/input/retinal-fundus-dr/retinal-dr-n/retinal-dr-n'\n",
    "IMG_SIZE = 224   # Reduced to standard size to prevent OOM\n",
    "BATCH_SIZE = 32  # Standard batch size\n",
    "EPOCHS = 45      # Sufficient for convergence\n",
    "LR = 1e-4        # Standard learning rate\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"ðŸš€ Starting Research Run on {DEVICE}...\")\n",
    "\n",
    "# --- 1. ROBUST DATASET (Handles your messy files) ---\n",
    "class RetinalDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        self.class_map = {\"Normal Fundus\": 0, \"Mild DR\": 1, \"Moderate DR\": 2, \"Severe DR\": 3, \"Proliferate DR\": 4}\n",
    "        \n",
    "        for cls_name, label in self.class_map.items():\n",
    "            folder = os.path.join(self.root_dir, cls_name)\n",
    "            if not os.path.exists(folder): continue\n",
    "            for f in os.listdir(folder):\n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    self.samples.append((os.path.join(folder, f), label))\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, label\n",
    "\n",
    "# Augmentation\n",
    "transform = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Loaders with Imbalance Fix\n",
    "train_ds = RetinalDataset(ROOT_DIR, 'train', transform)\n",
    "val_ds = RetinalDataset(ROOT_DIR, 'val', transform)\n",
    "\n",
    "# Weighted Sampler\n",
    "targets = [s[1] for s in train_ds.samples]\n",
    "counts = np.bincount(targets)\n",
    "weights = 1. / counts\n",
    "sample_weights = [weights[t] for t in targets]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"âœ… Data Loaded: {len(train_ds)} Training, {len(val_ds)} Validation\")\n",
    "\n",
    "# --- 2. MODEL: Simplified MambaVision (Pure PyTorch) ---\n",
    "class MambaBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.in_proj = nn.Linear(dim, 2 * dim)\n",
    "        self.conv1d = nn.Conv1d(dim, dim, 3, padding=1, groups=dim) # Standard Conv\n",
    "        self.out_proj = nn.Linear(dim, dim)\n",
    "        self.act = nn.SiLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [B, L, D]\n",
    "        B, L, D = x.shape\n",
    "        x_and_z = self.in_proj(x)\n",
    "        x_branch, z_branch = x_and_z.chunk(2, dim=-1)\n",
    "        \n",
    "        # Conv Branch\n",
    "        x_branch = x_branch.transpose(1, 2)\n",
    "        x_branch = self.act(self.conv1d(x_branch))\n",
    "        x_branch = x_branch.transpose(1, 2)\n",
    "        \n",
    "        # Simplified Gating (No complex SSM to avoid CUDA errors)\n",
    "        # This approximates the mixing behavior for visual tasks\n",
    "        y = x_branch * F.sigmoid(z_branch)\n",
    "        return self.out_proj(y)\n",
    "\n",
    "class MambaVisionSimple(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super().__init__()\n",
    "        # 1. Stem (CNN for features)\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, stride=2, padding=3), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1), nn.BatchNorm2d(128), nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 2. Body (Mamba Blocks)\n",
    "        self.blocks = nn.ModuleList([MambaBlock(128) for _ in range(6)])\n",
    "        \n",
    "        # 3. Head\n",
    "        self.norm = nn.LayerNorm(128)\n",
    "        self.head = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract features (CNN)\n",
    "        x = self.stem(x) # [B, 128, H/8, W/8]\n",
    "        \n",
    "        # Flatten for Mamba\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2) # [B, L, C]\n",
    "        \n",
    "        # Process (Mamba)\n",
    "        for block in self.blocks:\n",
    "            x = x + block(x)\n",
    "            \n",
    "        # Classify\n",
    "        x = self.norm(x.mean(dim=1))\n",
    "        return self.head(x)\n",
    "\n",
    "model = MambaVisionSimple(num_classes=5).to(DEVICE)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler() # Mixed Precision\n",
    "\n",
    "# --- 3. TRAINING LOOP (With Graphs) ---\n",
    "history = {'loss': [], 'acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for img, label in pbar:\n",
    "        img, label = img.to(DEVICE), label.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with autocast(): # Faster & Less Memory\n",
    "            out = model(img)\n",
    "            loss = criterion(out, label)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        preds = out.argmax(dim=1)\n",
    "        correct += (preds == label).sum().item()\n",
    "        total += label.size(0)\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    history['loss'].append(total_loss / len(train_loader))\n",
    "    history['acc'].append(correct / total)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct, val_total, val_loss = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for img, label in val_loader:\n",
    "            img, label = img.to(DEVICE), label.to(DEVICE)\n",
    "            out = model(img)\n",
    "            val_loss += criterion(out, label).item()\n",
    "            val_correct += (out.argmax(1) == label).sum().item()\n",
    "            val_total += label.size(0)\n",
    "            \n",
    "    val_acc = val_correct / val_total\n",
    "    history['val_loss'].append(val_loss / len(val_loader))\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    print(f\"Validation Acc: {val_acc:.4f}\")\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "# --- 4. RESEARCH OUTPUTS ---\n",
    "# Plot Curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1,2,1); plt.plot(history['loss'], label='Train'); plt.plot(history['val_loss'], label='Val'); plt.title(\"Loss\"); plt.legend()\n",
    "plt.subplot(1,2,2); plt.plot(history['acc'], label='Train'); plt.plot(history['val_acc'], label='Val'); plt.title(\"Accuracy\"); plt.legend()\n",
    "plt.savefig(\"training_graphs.png\")\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "with torch.no_grad():\n",
    "    for img, label in val_loader:\n",
    "        img, label = img.to(DEVICE), label.to(DEVICE)\n",
    "        all_preds.extend(model(img).argmax(1).cpu().numpy())\n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=train_ds.class_map.keys(), yticklabels=train_ds.class_map.keys())\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFinal Report:\\n\", classification_report(all_labels, all_preds, target_names=train_ds.class_map.keys()))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
